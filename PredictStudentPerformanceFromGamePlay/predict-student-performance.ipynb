{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69f35ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入需要使用的库\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x) \n",
    "# pd.set_option('display.max_columns',50) #设置显示的最大列数，同时，也可以根据需要通过set_option函数设置其他的属性\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ddc231",
   "metadata": {},
   "source": [
    "## 载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c277e265",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1) 载入训练集和测试集；\n",
    "#remember to change the path to csv files each time before using this template\n",
    "#path = 'C:/Users/87495/Desktop/Kaggle/predict-student-performance-from-game-play/'\n",
    "path = 'D:/Code area/python area/kagglestuff/PredictStudentPerformanceFromGamePlay/'\n",
    "Train_data = pd.read_csv(path+'train.csv', sep=',')\n",
    "Test_data = pd.read_csv(path+'test.csv', sep=',')\n",
    "Train_labels = pd.read_csv(path+'train_labels.csv', sep=',')\n",
    "# Sampele_submission = pd.read_csv(path+'sample_submission.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171043ab",
   "metadata": {},
   "source": [
    "# 通过调整数据类型，帮助我们减少数据在内存中占用的空间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "605f172f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce_mem_usage 函数通过调整数据类型，帮助我们减少数据在内存中占用的空间\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() \n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() \n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f46872c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 2107873888.00 MB\n",
      "Memory usage after optimization is: 816834322.00 MB\n",
      "Decreased by 61.2%\n"
     ]
    }
   ],
   "source": [
    "Train_data = reduce_mem_usage(Train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44aef9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 626432.00 MB\n",
      "Memory usage after optimization is: 254036.00 MB\n",
      "Decreased by 59.4%\n"
     ]
    }
   ],
   "source": [
    "Test_data = reduce_mem_usage(Test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b95577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并方便后面的操作\n",
    "df = pd.concat([Train_data, Test_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1320d5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>index</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>event_name</th>\n",
       "      <th>name</th>\n",
       "      <th>level</th>\n",
       "      <th>page</th>\n",
       "      <th>room_coor_x</th>\n",
       "      <th>room_coor_y</th>\n",
       "      <th>screen_coor_x</th>\n",
       "      <th>screen_coor_y</th>\n",
       "      <th>hover_duration</th>\n",
       "      <th>text</th>\n",
       "      <th>fqid</th>\n",
       "      <th>room_fqid</th>\n",
       "      <th>text_fqid</th>\n",
       "      <th>fullscreen</th>\n",
       "      <th>hq</th>\n",
       "      <th>music</th>\n",
       "      <th>level_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cutscene_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-414.0000</td>\n",
       "      <td>-159.3750</td>\n",
       "      <td>380.0000</td>\n",
       "      <td>494.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>undefined</td>\n",
       "      <td>intro</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.intro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>1</td>\n",
       "      <td>1323</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-414.0000</td>\n",
       "      <td>-159.3750</td>\n",
       "      <td>380.0000</td>\n",
       "      <td>494.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Whatcha doing over there, Jo?</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>2</td>\n",
       "      <td>831</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-414.0000</td>\n",
       "      <td>-159.3750</td>\n",
       "      <td>380.0000</td>\n",
       "      <td>494.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just talking to Teddy.</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>3</td>\n",
       "      <td>1147</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-414.0000</td>\n",
       "      <td>-159.3750</td>\n",
       "      <td>380.0000</td>\n",
       "      <td>494.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I gotta run to my meeting!</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>4</td>\n",
       "      <td>1863</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-413.0000</td>\n",
       "      <td>-159.3750</td>\n",
       "      <td>381.0000</td>\n",
       "      <td>494.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Can I come, Gramps?</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13174206</th>\n",
       "      <td>22100221145014656</td>\n",
       "      <td>1600</td>\n",
       "      <td>5483231</td>\n",
       "      <td>navigate_click</td>\n",
       "      <td>undefined</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>344.0000</td>\n",
       "      <td>36.6875</td>\n",
       "      <td>483.0000</td>\n",
       "      <td>273.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tunic.capitol_2.hall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13174207</th>\n",
       "      <td>22100221145014656</td>\n",
       "      <td>1601</td>\n",
       "      <td>5485166</td>\n",
       "      <td>navigate_click</td>\n",
       "      <td>undefined</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>332.7500</td>\n",
       "      <td>141.5000</td>\n",
       "      <td>545.0000</td>\n",
       "      <td>221.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chap4_finale_c</td>\n",
       "      <td>tunic.capitol_2.hall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13174208</th>\n",
       "      <td>22100221145014656</td>\n",
       "      <td>1602</td>\n",
       "      <td>5485917</td>\n",
       "      <td>navigate_click</td>\n",
       "      <td>undefined</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>370.0000</td>\n",
       "      <td>140.6250</td>\n",
       "      <td>611.0000</td>\n",
       "      <td>217.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tunic.capitol_2.hall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13174209</th>\n",
       "      <td>22100221145014656</td>\n",
       "      <td>1603</td>\n",
       "      <td>5486753</td>\n",
       "      <td>navigate_click</td>\n",
       "      <td>undefined</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>252.2500</td>\n",
       "      <td>123.8125</td>\n",
       "      <td>526.0000</td>\n",
       "      <td>232.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chap4_finale_c</td>\n",
       "      <td>tunic.capitol_2.hall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13174210</th>\n",
       "      <td>22100221145014656</td>\n",
       "      <td>1604</td>\n",
       "      <td>5487952</td>\n",
       "      <td>checkpoint</td>\n",
       "      <td>basic</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chap4_finale_c</td>\n",
       "      <td>tunic.capitol_2.hall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 session_id  index  elapsed_time      event_name       name  \\\n",
       "0         20090312431273200      0             0  cutscene_click      basic   \n",
       "1         20090312431273200      1          1323    person_click      basic   \n",
       "2         20090312431273200      2           831    person_click      basic   \n",
       "3         20090312431273200      3          1147    person_click      basic   \n",
       "4         20090312431273200      4          1863    person_click      basic   \n",
       "13174206  22100221145014656   1600       5483231  navigate_click  undefined   \n",
       "13174207  22100221145014656   1601       5485166  navigate_click  undefined   \n",
       "13174208  22100221145014656   1602       5485917  navigate_click  undefined   \n",
       "13174209  22100221145014656   1603       5486753  navigate_click  undefined   \n",
       "13174210  22100221145014656   1604       5487952      checkpoint      basic   \n",
       "\n",
       "          level  page  room_coor_x  room_coor_y  screen_coor_x  screen_coor_y  \\\n",
       "0             0   NaN    -414.0000    -159.3750       380.0000       494.0000   \n",
       "1             0   NaN    -414.0000    -159.3750       380.0000       494.0000   \n",
       "2             0   NaN    -414.0000    -159.3750       380.0000       494.0000   \n",
       "3             0   NaN    -414.0000    -159.3750       380.0000       494.0000   \n",
       "4             0   NaN    -413.0000    -159.3750       381.0000       494.0000   \n",
       "13174206     22   NaN     344.0000      36.6875       483.0000       273.0000   \n",
       "13174207     22   NaN     332.7500     141.5000       545.0000       221.0000   \n",
       "13174208     22   NaN     370.0000     140.6250       611.0000       217.0000   \n",
       "13174209     22   NaN     252.2500     123.8125       526.0000       232.0000   \n",
       "13174210     22   NaN          NaN          NaN            NaN            NaN   \n",
       "\n",
       "          hover_duration                           text            fqid  \\\n",
       "0                    NaN                      undefined           intro   \n",
       "1                    NaN  Whatcha doing over there, Jo?          gramps   \n",
       "2                    NaN         Just talking to Teddy.          gramps   \n",
       "3                    NaN     I gotta run to my meeting!          gramps   \n",
       "4                    NaN            Can I come, Gramps?          gramps   \n",
       "13174206             NaN                            NaN             NaN   \n",
       "13174207             NaN                            NaN  chap4_finale_c   \n",
       "13174208             NaN                            NaN             NaN   \n",
       "13174209             NaN                            NaN  chap4_finale_c   \n",
       "13174210             NaN                            NaN  chap4_finale_c   \n",
       "\n",
       "                               room_fqid  \\\n",
       "0         tunic.historicalsociety.closet   \n",
       "1         tunic.historicalsociety.closet   \n",
       "2         tunic.historicalsociety.closet   \n",
       "3         tunic.historicalsociety.closet   \n",
       "4         tunic.historicalsociety.closet   \n",
       "13174206            tunic.capitol_2.hall   \n",
       "13174207            tunic.capitol_2.hall   \n",
       "13174208            tunic.capitol_2.hall   \n",
       "13174209            tunic.capitol_2.hall   \n",
       "13174210            tunic.capitol_2.hall   \n",
       "\n",
       "                                                  text_fqid  fullscreen  hq  \\\n",
       "0                      tunic.historicalsociety.closet.intro         NaN NaN   \n",
       "1         tunic.historicalsociety.closet.gramps.intro_0_...         NaN NaN   \n",
       "2         tunic.historicalsociety.closet.gramps.intro_0_...         NaN NaN   \n",
       "3         tunic.historicalsociety.closet.gramps.intro_0_...         NaN NaN   \n",
       "4         tunic.historicalsociety.closet.gramps.intro_0_...         NaN NaN   \n",
       "13174206                                                NaN         NaN NaN   \n",
       "13174207                                                NaN         NaN NaN   \n",
       "13174208                                                NaN         NaN NaN   \n",
       "13174209                                                NaN         NaN NaN   \n",
       "13174210                                                NaN         NaN NaN   \n",
       "\n",
       "          music level_group  \n",
       "0           NaN         0-4  \n",
       "1           NaN         0-4  \n",
       "2           NaN         0-4  \n",
       "3           NaN         0-4  \n",
       "4           NaN         0-4  \n",
       "13174206    NaN       13-22  \n",
       "13174207    NaN       13-22  \n",
       "13174208    NaN       13-22  \n",
       "13174209    NaN       13-22  \n",
       "13174210    NaN       13-22  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2) 简略观察数据(head()+shape)\n",
    "Train_data.head().append(Train_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5638a3e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13174211, 20)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "213a1f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>index</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>event_name</th>\n",
       "      <th>name</th>\n",
       "      <th>level</th>\n",
       "      <th>page</th>\n",
       "      <th>room_coor_x</th>\n",
       "      <th>room_coor_y</th>\n",
       "      <th>screen_coor_x</th>\n",
       "      <th>screen_coor_y</th>\n",
       "      <th>hover_duration</th>\n",
       "      <th>text</th>\n",
       "      <th>fqid</th>\n",
       "      <th>room_fqid</th>\n",
       "      <th>text_fqid</th>\n",
       "      <th>fullscreen</th>\n",
       "      <th>hq</th>\n",
       "      <th>music</th>\n",
       "      <th>level_group</th>\n",
       "      <th>session_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090109393214576</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cutscene_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-414.0000</td>\n",
       "      <td>75.6875</td>\n",
       "      <td>380.0000</td>\n",
       "      <td>259.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>undefined</td>\n",
       "      <td>intro</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.intro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "      <td>20090109393214576_0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090109393214576</td>\n",
       "      <td>1</td>\n",
       "      <td>1965</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-106.0000</td>\n",
       "      <td>-63.3125</td>\n",
       "      <td>688.0000</td>\n",
       "      <td>398.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Whatcha doing over there, Jo?</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "      <td>20090109393214576_0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090109393214576</td>\n",
       "      <td>2</td>\n",
       "      <td>3614</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-419.0000</td>\n",
       "      <td>47.6875</td>\n",
       "      <td>375.0000</td>\n",
       "      <td>287.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just talking to Teddy.</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "      <td>20090109393214576_0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20090109393214576</td>\n",
       "      <td>3</td>\n",
       "      <td>5330</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-111.0000</td>\n",
       "      <td>-57.3125</td>\n",
       "      <td>683.0000</td>\n",
       "      <td>392.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I gotta run to my meeting!</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "      <td>20090109393214576_0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20090109393214576</td>\n",
       "      <td>4</td>\n",
       "      <td>6397</td>\n",
       "      <td>person_click</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-111.0000</td>\n",
       "      <td>-57.3125</td>\n",
       "      <td>683.0000</td>\n",
       "      <td>392.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Can I come, Gramps?</td>\n",
       "      <td>gramps</td>\n",
       "      <td>tunic.historicalsociety.closet</td>\n",
       "      <td>tunic.historicalsociety.closet.gramps.intro_0_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-4</td>\n",
       "      <td>20090109393214576_0-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13174206</th>\n",
       "      <td>22100221145014656</td>\n",
       "      <td>1600</td>\n",
       "      <td>5483231</td>\n",
       "      <td>navigate_click</td>\n",
       "      <td>undefined</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>344.0000</td>\n",
       "      <td>36.6875</td>\n",
       "      <td>483.0000</td>\n",
       "      <td>273.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tunic.capitol_2.hall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13-22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13174207</th>\n",
       "      <td>22100221145014656</td>\n",
       "      <td>1601</td>\n",
       "      <td>5485166</td>\n",
       "      <td>navigate_click</td>\n",
       "      <td>undefined</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>332.7500</td>\n",
       "      <td>141.5000</td>\n",
       "      <td>545.0000</td>\n",
       "      <td>221.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chap4_finale_c</td>\n",
       "      <td>tunic.capitol_2.hall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13-22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13174208</th>\n",
       "      <td>22100221145014656</td>\n",
       "      <td>1602</td>\n",
       "      <td>5485917</td>\n",
       "      <td>navigate_click</td>\n",
       "      <td>undefined</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>370.0000</td>\n",
       "      <td>140.6250</td>\n",
       "      <td>611.0000</td>\n",
       "      <td>217.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tunic.capitol_2.hall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13-22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13174209</th>\n",
       "      <td>22100221145014656</td>\n",
       "      <td>1603</td>\n",
       "      <td>5486753</td>\n",
       "      <td>navigate_click</td>\n",
       "      <td>undefined</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>252.2500</td>\n",
       "      <td>123.8125</td>\n",
       "      <td>526.0000</td>\n",
       "      <td>232.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chap4_finale_c</td>\n",
       "      <td>tunic.capitol_2.hall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13-22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13174210</th>\n",
       "      <td>22100221145014656</td>\n",
       "      <td>1604</td>\n",
       "      <td>5487952</td>\n",
       "      <td>checkpoint</td>\n",
       "      <td>basic</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chap4_finale_c</td>\n",
       "      <td>tunic.capitol_2.hall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13-22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 session_id  index  elapsed_time      event_name       name  \\\n",
       "0         20090109393214576      0             0  cutscene_click      basic   \n",
       "1         20090109393214576      1          1965    person_click      basic   \n",
       "2         20090109393214576      2          3614    person_click      basic   \n",
       "3         20090109393214576      3          5330    person_click      basic   \n",
       "4         20090109393214576      4          6397    person_click      basic   \n",
       "13174206  22100221145014656   1600       5483231  navigate_click  undefined   \n",
       "13174207  22100221145014656   1601       5485166  navigate_click  undefined   \n",
       "13174208  22100221145014656   1602       5485917  navigate_click  undefined   \n",
       "13174209  22100221145014656   1603       5486753  navigate_click  undefined   \n",
       "13174210  22100221145014656   1604       5487952      checkpoint      basic   \n",
       "\n",
       "          level  page  room_coor_x  room_coor_y  screen_coor_x  screen_coor_y  \\\n",
       "0             0   NaN    -414.0000      75.6875       380.0000       259.0000   \n",
       "1             0   NaN    -106.0000     -63.3125       688.0000       398.0000   \n",
       "2             0   NaN    -419.0000      47.6875       375.0000       287.0000   \n",
       "3             0   NaN    -111.0000     -57.3125       683.0000       392.0000   \n",
       "4             0   NaN    -111.0000     -57.3125       683.0000       392.0000   \n",
       "13174206     22   NaN     344.0000      36.6875       483.0000       273.0000   \n",
       "13174207     22   NaN     332.7500     141.5000       545.0000       221.0000   \n",
       "13174208     22   NaN     370.0000     140.6250       611.0000       217.0000   \n",
       "13174209     22   NaN     252.2500     123.8125       526.0000       232.0000   \n",
       "13174210     22   NaN          NaN          NaN            NaN            NaN   \n",
       "\n",
       "          hover_duration                           text            fqid  \\\n",
       "0                    NaN                      undefined           intro   \n",
       "1                    NaN  Whatcha doing over there, Jo?          gramps   \n",
       "2                    NaN         Just talking to Teddy.          gramps   \n",
       "3                    NaN     I gotta run to my meeting!          gramps   \n",
       "4                    NaN            Can I come, Gramps?          gramps   \n",
       "13174206             NaN                            NaN             NaN   \n",
       "13174207             NaN                            NaN  chap4_finale_c   \n",
       "13174208             NaN                            NaN             NaN   \n",
       "13174209             NaN                            NaN  chap4_finale_c   \n",
       "13174210             NaN                            NaN  chap4_finale_c   \n",
       "\n",
       "                               room_fqid  \\\n",
       "0         tunic.historicalsociety.closet   \n",
       "1         tunic.historicalsociety.closet   \n",
       "2         tunic.historicalsociety.closet   \n",
       "3         tunic.historicalsociety.closet   \n",
       "4         tunic.historicalsociety.closet   \n",
       "13174206            tunic.capitol_2.hall   \n",
       "13174207            tunic.capitol_2.hall   \n",
       "13174208            tunic.capitol_2.hall   \n",
       "13174209            tunic.capitol_2.hall   \n",
       "13174210            tunic.capitol_2.hall   \n",
       "\n",
       "                                                  text_fqid  fullscreen  hq  \\\n",
       "0                      tunic.historicalsociety.closet.intro         NaN NaN   \n",
       "1         tunic.historicalsociety.closet.gramps.intro_0_...         NaN NaN   \n",
       "2         tunic.historicalsociety.closet.gramps.intro_0_...         NaN NaN   \n",
       "3         tunic.historicalsociety.closet.gramps.intro_0_...         NaN NaN   \n",
       "4         tunic.historicalsociety.closet.gramps.intro_0_...         NaN NaN   \n",
       "13174206                                                NaN         NaN NaN   \n",
       "13174207                                                NaN         NaN NaN   \n",
       "13174208                                                NaN         NaN NaN   \n",
       "13174209                                                NaN         NaN NaN   \n",
       "13174210                                                NaN         NaN NaN   \n",
       "\n",
       "          music level_group          session_level  \n",
       "0           NaN         0-4  20090109393214576_0-4  \n",
       "1           NaN         0-4  20090109393214576_0-4  \n",
       "2           NaN         0-4  20090109393214576_0-4  \n",
       "3           NaN         0-4  20090109393214576_0-4  \n",
       "4           NaN         0-4  20090109393214576_0-4  \n",
       "13174206    NaN       13-22                    NaN  \n",
       "13174207    NaN       13-22                    NaN  \n",
       "13174208    NaN       13-22                    NaN  \n",
       "13174209    NaN       13-22                    NaN  \n",
       "13174210    NaN       13-22                    NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_data.head().append(Train_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca2d845c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3728, 21)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c2743f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c126fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83d7860a",
   "metadata": {},
   "source": [
    "## 总览数据情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad83f6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#describe种有每列的统计量，个数count、平均值mean、方差std、最小值min、中位数25% 50% 75% 、以及最大值\n",
    "#看这个信息主要是瞬间掌握数据的大概的范围以及每个值的异常值的判断，\n",
    "#比如有的时候会发现999 9999 -1 等值这些其实都是nan的另外一种表达方式，有的时候需要注意下\n",
    "#info 通过info来了解数据每列的type，有助于了解是否存在除了nan以外的特殊符号异常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dad24a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>index</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>level</th>\n",
       "      <th>page</th>\n",
       "      <th>room_coor_x</th>\n",
       "      <th>room_coor_y</th>\n",
       "      <th>screen_coor_x</th>\n",
       "      <th>screen_coor_y</th>\n",
       "      <th>hover_duration</th>\n",
       "      <th>fullscreen</th>\n",
       "      <th>hq</th>\n",
       "      <th>music</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13174211.0000</td>\n",
       "      <td>13174211.0000</td>\n",
       "      <td>13174211.0000</td>\n",
       "      <td>13174211.0000</td>\n",
       "      <td>284746.0000</td>\n",
       "      <td>12137971.0000</td>\n",
       "      <td>12137971.0000</td>\n",
       "      <td>12137971.0000</td>\n",
       "      <td>12137971.0000</td>\n",
       "      <td>1000737.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>21134134855458160.0000</td>\n",
       "      <td>652.6426</td>\n",
       "      <td>3846817.2860</td>\n",
       "      <td>12.1919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3186.2383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>566522042999546.6250</td>\n",
       "      <td>627.5818</td>\n",
       "      <td>27013866.5246</td>\n",
       "      <td>6.4992</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>369226.5312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20090312431273200.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1992.0000</td>\n",
       "      <td>-918.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21010310162137956.0000</td>\n",
       "      <td>289.0000</td>\n",
       "      <td>439430.0000</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>-353.0000</td>\n",
       "      <td>-212.8750</td>\n",
       "      <td>269.0000</td>\n",
       "      <td>304.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21040215432620068.0000</td>\n",
       "      <td>596.0000</td>\n",
       "      <td>1013425.0000</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>-11.1641</td>\n",
       "      <td>-97.8125</td>\n",
       "      <td>447.0000</td>\n",
       "      <td>397.0000</td>\n",
       "      <td>418.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21100514325903272.0000</td>\n",
       "      <td>897.0000</td>\n",
       "      <td>1740050.0000</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>296.2500</td>\n",
       "      <td>22.6875</td>\n",
       "      <td>663.0000</td>\n",
       "      <td>471.0000</td>\n",
       "      <td>1266.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22100221145014656.0000</td>\n",
       "      <td>20473.0000</td>\n",
       "      <td>1749293395.0000</td>\n",
       "      <td>22.0000</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>1262.0000</td>\n",
       "      <td>543.5000</td>\n",
       "      <td>1916.0000</td>\n",
       "      <td>1439.0000</td>\n",
       "      <td>219907808.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  session_id         index    elapsed_time         level  \\\n",
       "count          13174211.0000 13174211.0000   13174211.0000 13174211.0000   \n",
       "mean  21134134855458160.0000      652.6426    3846817.2860       12.1919   \n",
       "std     566522042999546.6250      627.5818   27013866.5246        6.4992   \n",
       "min   20090312431273200.0000        0.0000          0.0000        0.0000   \n",
       "25%   21010310162137956.0000      289.0000     439430.0000        6.0000   \n",
       "50%   21040215432620068.0000      596.0000    1013425.0000       13.0000   \n",
       "75%   21100514325903272.0000      897.0000    1740050.0000       18.0000   \n",
       "max   22100221145014656.0000    20473.0000 1749293395.0000       22.0000   \n",
       "\n",
       "             page   room_coor_x   room_coor_y  screen_coor_x  screen_coor_y  \\\n",
       "count 284746.0000 12137971.0000 12137971.0000  12137971.0000  12137971.0000   \n",
       "mean          NaN           NaN           NaN            NaN            NaN   \n",
       "std        0.0000           NaN           NaN            NaN            NaN   \n",
       "min        0.0000    -1992.0000     -918.0000         0.0000         0.0000   \n",
       "25%        1.0000     -353.0000     -212.8750       269.0000       304.0000   \n",
       "50%        3.0000      -11.1641      -97.8125       447.0000       397.0000   \n",
       "75%        5.0000      296.2500       22.6875       663.0000       471.0000   \n",
       "max        6.0000     1262.0000      543.5000      1916.0000      1439.0000   \n",
       "\n",
       "       hover_duration  fullscreen     hq  music  \n",
       "count    1000737.0000      0.0000 0.0000 0.0000  \n",
       "mean        3186.2383         NaN    NaN    NaN  \n",
       "std       369226.5312         NaN    NaN    NaN  \n",
       "min            0.0000         NaN    NaN    NaN  \n",
       "25%          100.0000         NaN    NaN    NaN  \n",
       "50%          418.0000         NaN    NaN    NaN  \n",
       "75%         1266.0000         NaN    NaN    NaN  \n",
       "max    219907808.0000         NaN    NaN    NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 1) 通过describe()来熟悉数据的相关统计量\n",
    "Train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d2a4c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13174211 entries, 0 to 13174210\n",
      "Data columns (total 20 columns):\n",
      " #   Column          Dtype   \n",
      "---  ------          -----   \n",
      " 0   session_id      int64   \n",
      " 1   index           int16   \n",
      " 2   elapsed_time    int32   \n",
      " 3   event_name      category\n",
      " 4   name            category\n",
      " 5   level           int8    \n",
      " 6   page            float16 \n",
      " 7   room_coor_x     float16 \n",
      " 8   room_coor_y     float16 \n",
      " 9   screen_coor_x   float16 \n",
      " 10  screen_coor_y   float16 \n",
      " 11  hover_duration  float32 \n",
      " 12  text            category\n",
      " 13  fqid            category\n",
      " 14  room_fqid       category\n",
      " 15  text_fqid       category\n",
      " 16  fullscreen      float64 \n",
      " 17  hq              float64 \n",
      " 18  music           float64 \n",
      " 19  level_group     category\n",
      "dtypes: category(7), float16(5), float32(1), float64(3), int16(1), int32(1), int64(1), int8(1)\n",
      "memory usage: 779.0 MB\n"
     ]
    }
   ],
   "source": [
    "## 2) 通过info()来熟悉数据类型\n",
    "Train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2983daf2",
   "metadata": {},
   "source": [
    "## 转化数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b5a1499",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot cast object dtype to int32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mD:\\MiniConda\\lib\\site-packages\\pandas\\core\\arrays\\categorical.py:551\u001b[0m, in \u001b[0;36mCategorical.astype\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 551\u001b[0m     new_cats \u001b[38;5;241m=\u001b[39m \u001b[43mnew_cats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    552\u001b[0m     fill_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories\u001b[38;5;241m.\u001b[39m_na_value\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'checkpoint'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#astype\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m##只能转化全部为数字组成的数据\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#to_numeric\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# 如果为'coerce',则将无效解析设置为NaN;\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# 如果为'ignore',则无效的解析将返回输入;\u001b[39;00m\n\u001b[0;32m     13\u001b[0m pd\u001b[38;5;241m.\u001b[39mto_numeric(df,errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mD:\\MiniConda\\lib\\site-packages\\pandas\\core\\generic.py:6240\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6233\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6234\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[:, i]\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m   6235\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[0;32m   6236\u001b[0m     ]\n\u001b[0;32m   6238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6239\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6240\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6243\u001b[0m \u001b[38;5;66;03m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[1;32mD:\\MiniConda\\lib\\site-packages\\pandas\\core\\internals\\managers.py:448\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mastype\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, dtype, copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m--> 448\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\MiniConda\\lib\\site-packages\\pandas\\core\\internals\\managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m):\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[1;32mD:\\MiniConda\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:526\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    510\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    524\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m--> 526\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    529\u001b[0m newb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_block(new_values)\n",
      "File \u001b[1;32mD:\\MiniConda\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:299\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 299\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;66;03m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mD:\\MiniConda\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:227\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;66;03m# i.e. ExtensionArray\u001b[39;00m\n\u001b[1;32m--> 227\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    230\u001b[0m     values \u001b[38;5;241m=\u001b[39m astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32mD:\\MiniConda\\lib\\site-packages\\pandas\\core\\arrays\\categorical.py:562\u001b[0m, in \u001b[0;36mCategorical.astype\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[0;32m    558\u001b[0m         \u001b[38;5;167;01mTypeError\u001b[39;00m,  \u001b[38;5;66;03m# downstream error msg for CategoricalIndex is misleading\u001b[39;00m\n\u001b[0;32m    559\u001b[0m         \u001b[38;5;167;01mValueError\u001b[39;00m,\n\u001b[0;32m    560\u001b[0m     ):\n\u001b[0;32m    561\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot cast \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dtype to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 562\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    564\u001b[0m     result \u001b[38;5;241m=\u001b[39m take_nd(\n\u001b[0;32m    565\u001b[0m         new_cats, ensure_platform_int(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_codes), fill_value\u001b[38;5;241m=\u001b[39mfill_value\n\u001b[0;32m    566\u001b[0m     )\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot cast object dtype to int32"
     ]
    }
   ],
   "source": [
    "#astype\n",
    "df.astype(int) \n",
    "##只能转化全部为数字组成的数据\n",
    "\n",
    "#to_numeric\n",
    "##pandas.to_numeric(arg, errors='raise', downcast=None)  \n",
    "###默认返回dtype为float64或int64\n",
    "###errors:{'ignore'，'raise'，'coerce'}，\n",
    "# 默认为'raise'\n",
    "# 如果为'raise',则无效的解析将引发异常;\n",
    "# 如果为'coerce',则将无效解析设置为NaN;\n",
    "# 如果为'ignore',则无效的解析将返回输入;\n",
    "pd.to_numeric(df,errors='coerce')\n",
    "##将字符串类型的数据转化为浮点型，并将原数据中由字母组成的字符串强制转化为NaN，但它是一个浮点数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb74b34",
   "metadata": {},
   "source": [
    "## 构造函数去除字符串中非数字的字符 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d525e1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_money(value):\n",
    "    new_value=value.replace(\"$\",\"\").replace(\",\",\"\")\n",
    "    return float(new_value)\n",
    "df.apply(convert_money)\n",
    "#非数字字符替换为空不是空格\n",
    "convert_money1=lambda x: float(x.replace(\"%\",\"\"))\n",
    "df.apply(convert_money1)\n",
    "#lanbda函数（匿名函数）效果同上"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eff6f1c",
   "metadata": {},
   "source": [
    "## 将评价字段转换为数值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86525c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pj(value):\n",
    "    if \"万\" in value:\n",
    "        new_value=float(value.replace(\"万\",\"\"))*10000\n",
    "    else:\n",
    "        new_value=value.replace(\"+\",\"\")\n",
    "    return float(new_value)\n",
    "data['评价']=data['评价'].astype(str).apply(convert_pj)\n",
    "data['评价']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188deab3",
   "metadata": {},
   "source": [
    "## 数据的一致性检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30f0ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "strlist=[]\n",
    "for i in data['movie_name'].index:\n",
    "    if isinstance(data['movie_name'][i],str)==False:\n",
    "        strlist.append(i)\n",
    "data['movie_name'][strlist]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05571d71",
   "metadata": {},
   "source": [
    "## 处理重复值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37dd798",
   "metadata": {},
   "outputs": [],
   "source": [
    "#检查重复值\n",
    "df.duplicated(subset=[],keep='False')\n",
    "#subset：指明数据子集，即某个特征或几个特征\n",
    "# keep: 删除重复项并保留第一次出现的。取值可以为first last False\n",
    "#first:保留第一个 last:保留最后一个 False:所有重复数据都标记为True\n",
    "df.duplicated().any()#返回True，说明df有重复记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d031f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#删除重复值\n",
    "df.drop_duplicates(keep='last',inplace=False)\n",
    "#inplace=False生成一个删除了重复数据之后的新数据集，True会修改当前数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64570ec5",
   "metadata": {},
   "source": [
    "## 重复率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f45b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.duplicated()].count()/data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977d9023",
   "metadata": {},
   "source": [
    "## 处理缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b03078",
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看每列的存在nan情况\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bdc335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nan可视化\n",
    "missing = Train_data.isnull().sum()\n",
    "missing = missing[missing > 0]\n",
    "missing.sort_values(inplace=True)\n",
    "missing.plot.bar()\n",
    "#通过以上两句可以很直观的了解哪些列存在 “nan”, 并可以把nan的个数打印，主要的目的在于 nan存在的个数是否真的很大，\n",
    "#如果很小一般选择填充，如果使用lgb等树模型可以直接空缺，让树自己去优化，但如果nan存在的过多、可以考虑删掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0cc85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化看下缺省值\n",
    "#msno库使用说明：https://blog.csdn.net/Andy_shenzl/article/details/81633356\n",
    "import missingno as msno\n",
    "msno.matrix(Train_data.sample(250))\n",
    "msno.bar(Train_data.sample(1000))\n",
    "msno.heatmap(Train_data.sample(250))\n",
    "#missingno相关性热图措施无效的相关性：一个变量的存在或不存在如何强烈影响的另一个的存在：\n",
    "    # 我们看到X5与X1.1的缺失相关性为1，说明X5只要发生了缺失，那么X1.1也会缺失，\n",
    "    # X7和X8的相关性为-1，说明X7缺失的值，那么X8没有缺失；而X7没有缺失时，X8为缺失。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a670b7",
   "metadata": {},
   "source": [
    "## 空缺率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecabc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kql=(data.shape[0]-data.count())/data.count()\n",
    "data_kql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed8d9d3",
   "metadata": {},
   "source": [
    "# 进一步查看缺失特征中缺失率大于50%的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e30d3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "have_null_fea_dict = (data_train.isnull().sum()/len(data_train)).to_dict()\n",
    "fea_null_moreThanHalf = {}\n",
    "for key,value in have_null_fea_dict.items():\n",
    "    if value > 0.5:\n",
    "        fea_null_moreThanHalf[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d2e700",
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_null_moreThanHalf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177b5a64",
   "metadata": {},
   "source": [
    "## 删除缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6314b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()\n",
    "'''\n",
    "参数：\n",
    "axis:       default 0指行,1为列\n",
    "how:       {‘any’, ‘all’}, default ‘any’指带缺失值的所有行;'all’指清除全是缺失值的\n",
    "thresh:    int,保留含有int个非空值的行\n",
    "subset:   对特定的列进行缺失值删除处理\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14ebd42",
   "metadata": {},
   "source": [
    "## 填补缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def98dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna()\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "df=SimpleImputer(*, missing_values=nan, strategy=‘mean’, fill_value=None, verbose=0, copy=True, add_indicator=False)\n",
    "\n",
    "# 参数含义\n",
    "\n",
    "# missing_values：int, float, str, (默认)np.nan或是None, 即缺失值是什么。\n",
    "\n",
    "# strategy：空值填充的策略，共四种选择（默认）mean、median、most_frequent、constant。\n",
    "#     mean表示该列的缺失值由该列的均值填充。\n",
    "#     median为中位数，\n",
    "#     most_frequent为众数。\n",
    "#     constant表示将空值填充为自定义的值，但这个自定义的值要通过fill_value来定义。\n",
    "    \n",
    "# fill_value：str或数值，默认为Zone。\n",
    "#     当strategy == \"constant\"时，fill_value被用来替换所有出现的缺失值（missing_values）。\n",
    "#     fill_value为Zone，当处理的是数值数据时，缺失值（missing_values）会替换为0，对于字符串或对象数据类型则替换为\"missing_value\" 这一字符串。\n",
    "\n",
    "# verbose：int，（默认）0，控制imputer的冗长。\n",
    "\n",
    "# copy：boolean，（默认）True，表示对数据的副本进行处理，False对数据原地修改。\n",
    "\n",
    "# add_indicator：boolean，（默认）False，True则会在数据后面加入n列由0和1构成的同样大小的数据，0表示所在位置非缺失值，1表示所在位置为缺失值。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e44e96d",
   "metadata": {},
   "source": [
    "## 根据规律填补（机器学习模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddfae02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "df=pd.DataFrame({\n",
    "    \"one\":np.random.randint(1,100,10),\n",
    "    \"two\":[2,4,6,8,10,12,14,16,18,20],\n",
    "    \"three\":[5,9,13,np.nan,21,np.nan,29,33,37,41]\n",
    "})\n",
    "\n",
    "df_train=df.dropna() #训练集\n",
    "df_test=df[df['three'].isnull()]  #测试集,缺失值为需预测的值\n",
    "\n",
    "regr=LinearRegression()\n",
    "regr.fit(df_train['two'].values.reshape(-1,1),df_train['three'].values.reshape(-1,1))#训练出线性回归模型\n",
    "df_three_pred=regr.predict(df_test['two'].values.reshape(-1,1))#用训练好的模型预测缺失值\n",
    "\n",
    "#将所得数值填补到原数据集中\n",
    "df.loc[(df.three.isnull()),'three']=df_three_pred\n",
    "df\n",
    "#df.loc[ 行索引, 列索引]\n",
    "\n",
    "\n",
    "# z.reshape(-1)\n",
    "# array([ 1,  2,  3,  4])\n",
    "# z.reshape(-1,1)\n",
    "#  array([[ 1],\n",
    "#         [ 2],\n",
    "#         [ 3],\n",
    "#         [ 4]])\n",
    "# 让z变成只有一列，行数不知道多少，通过`z.reshape(-1,1)`，Numpy自动计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969f815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9272119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab53deab",
   "metadata": {},
   "source": [
    "## 删除异常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5efad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#以下两个类别特征严重倾斜，一般不会对预测有什么帮助，故这边先删掉，当然你也可以继续挖掘，但是一般意义不大\n",
    "Train_data[\"seller\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8640d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里我包装了一个异常值处理的代码，可以随便调用。\n",
    "def outliers_proc(data, col_name, scale=3):\n",
    "    \"\"\"\n",
    "    用于清洗异常值，默认用 box_plot（scale=3）进行清洗\n",
    "    :param data: 接收 pandas 数据格式\n",
    "    :param col_name: pandas 列名\n",
    "    :param scale: 尺度\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    def box_plot_outliers(data_ser, box_scale):\n",
    "        \"\"\"\n",
    "        利用箱线图去除异常值\n",
    "        :param data_ser: 接收 pandas.Series 数据格式\n",
    "        :param box_scale: 箱线图尺度，\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        iqr = box_scale * (data_ser.quantile(0.75) - data_ser.quantile(0.25))\n",
    "        val_low = data_ser.quantile(0.25) - iqr\n",
    "        val_up = data_ser.quantile(0.75) + iqr\n",
    "        rule_low = (data_ser < val_low)\n",
    "        rule_up = (data_ser > val_up)\n",
    "        return (rule_low, rule_up), (val_low, val_up)\n",
    "\n",
    "    data_n = data.copy()\n",
    "    data_series = data_n[col_name]\n",
    "    rule, value = box_plot_outliers(data_series, box_scale=scale)\n",
    "    index = np.arange(data_series.shape[0])[rule[0] | rule[1]]\n",
    "    print(\"Delete number is: {}\".format(len(index)))\n",
    "    data_n = data_n.drop(index)\n",
    "    data_n.reset_index(drop=True, inplace=True)\n",
    "    print(\"Now column number is: {}\".format(data_n.shape[0]))\n",
    "    index_low = np.arange(data_series.shape[0])[rule[0]]\n",
    "    outliers = data_series.iloc[index_low]\n",
    "    print(\"Description of data less than the lower bound is:\")\n",
    "    print(pd.Series(outliers).describe())\n",
    "    index_up = np.arange(data_series.shape[0])[rule[1]]\n",
    "    outliers = data_series.iloc[index_up]\n",
    "    print(\"Description of data larger than the upper bound is:\")\n",
    "    print(pd.Series(outliers).describe())\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 7))\n",
    "    sns.boxplot(y=data[col_name], data=data, palette=\"Set1\", ax=ax[0])\n",
    "    sns.boxplot(y=data_n[col_name], data=data_n, palette=\"Set1\", ax=ax[1])\n",
    "    return data_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b345dcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们可以删掉一些异常数据，以 power 为例。  \n",
    "# 这里删不删同学可以自行判断\n",
    "# 但是要注意 test 的数据不能删 = = 不能掩耳盗铃是不是\n",
    "\n",
    "Train_data = outliers_proc(Train_data, 'power', scale=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252c1171",
   "metadata": {},
   "source": [
    "## OneHot编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bb2f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "persons=pd.DataFrame({'name':['newton','andrew','jodn','bill'],'color':['yellow','white','black','white']})\n",
    "print(persons)\n",
    "df_dum=pd.get_dummies(persons['color'])\n",
    "print(df_dum)\n",
    "persons1=pd.concat([persons,df_dum],axis=1)\n",
    "print(persons1)\n",
    "#或者这一种简写\n",
    "persons2 = pd.get_dummies(persons, columns=['color'])\n",
    "print(persons2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bdd706",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(data, prefix=None, prefix_sep='_', dummy_na=False, columns=None, sparse=False, drop_first=False)[source]\n",
    "# data ： array-like，Series或DataFrame\n",
    "\n",
    "# prefix ：string，字符串列表或字符串dict，默认为None，\n",
    "\n",
    "# 用于追加DataFrame列名的字符串。在DataFrame上调用get_dummies时，传递一个长度等于列数的列表。或者，前缀 可以是将列名称映射到前缀的字典。\n",
    "\n",
    "# prefix_sep ： string，默认为’_’\n",
    "\n",
    "# 如果附加前缀，分隔符/分隔符要使用。或者传递与前缀一样的列表或字典。\n",
    "\n",
    "# dummy_na ： bool，默认为False\n",
    "# 如果忽略False NaN，则添加一列以指示NaN。\n",
    "\n",
    "# columns ： 类似列表，默认为无\n",
    "# 要编码的DataFrame中的列名称。如果列是None，那么所有与列 对象或类别 D型细胞将被转换。\n",
    "\n",
    "# sparse ： bool，默认为False\n",
    "# 伪编码列是否应由SparseArray（True）或常规NumPy数组（False）支持。\n",
    "\n",
    "# drop_first ： bool，默认为False\n",
    "# 是否通过删除第一级别从k分类级别获得k-1个假人。\n",
    "\n",
    "print(pd.get_dummies(persons))\n",
    "print(pd.get_dummies(persons,prefix='haha',prefix_sep='*'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aabaf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "persons=pd.concat([persons,df_dum],axis=1)\n",
    "persons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f74a53",
   "metadata": {},
   "source": [
    "## 数据离散化（分箱）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673db387",
   "metadata": {},
   "outputs": [],
   "source": [
    "#无监督离散化\n",
    "ages=pd.DataFrame({'years':[10,140,30,53,67,32,45],'name':['a1','a2','a3','a4','a5','a6','a7']})\n",
    "print(ages)\n",
    "ages['label']=pd.cut(ages['years'],3)\n",
    "print(ages)\n",
    "ages['label']=pd.cut(ages['years'],3,labels=['青年','中年','老年']) #等宽分箱\n",
    "print(ages)\n",
    "ages['label']=pd.cut(ages['years'],bins=[9,20,50,200],labels=['青年','中年','老年'])  #bins不等宽分箱\n",
    "print(ages)\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "kbd=KBinsDiscretizer(n_bins=3,encode='ordinal',strategy='uniform')\n",
    "#n_bins：表示所划分的区间个数（整数）\n",
    "#encode：表示离散化后的结果保存方式\n",
    "#     onehot：离散化后OnheHot编码，返回一个稀疏矩阵\n",
    "#     onehot-dense：离散化后OnheHot编码，返回一个数组\n",
    "#     ordinal:离散化后,以整数数值标记相应的记录\n",
    "# strategy:离散化策略\n",
    "#     uniform:分区的宽度相同\n",
    "#     quantile:默认值,分区样本数量相同\n",
    "#     kmeans:k-means聚类算法设置分区\n",
    "\n",
    "ages=pd.DataFrame({'years':[10,140,30,53,67,32,45],'name':['a1','a2','a3','a4','a5','a6','a7']})\n",
    "trans=kbd.fit_transform(ages[['years']])\n",
    "ages['kbd']=trans[:,0]\n",
    "print(ages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72977ad",
   "metadata": {},
   "source": [
    "# 了解预测值分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3654eb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a709fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data['price'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01aea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1) 总体分布概况（无界约翰逊分布等）\n",
    "import scipy.stats as st\n",
    "y = Train_data['price']\n",
    "plt.figure(1); plt.title('Johnson SU')\n",
    "sns.distplot(y, kde=False, fit=st.johnsonsu)\n",
    "plt.figure(2); plt.title('Normal')\n",
    "sns.distplot(y, kde=False, fit=st.norm)\n",
    "plt.figure(3); plt.title('Log Normal')\n",
    "sns.distplot(y, kde=False, fit=st.lognorm)\n",
    "#价格不服从正态分布，所以在进行回归之前，它必须进行转换。虽然对数变换做得很好，但最佳拟合是无界约翰逊分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b19e228",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2) 查看skewness and kurtosis\n",
    "sns.distplot(Train_data['price']);\n",
    "print(\"Skewness: %f\" % Train_data['price'].skew())\n",
    "#数据的不对称程度 \n",
    "#Skewness> 0,正偏差数值较大，为正偏或右偏。长尾巴拖在右边，数据右端有较多的极端值。\n",
    "#Skewness < 0 ，负偏差数值较大，为负偏或左偏。长尾巴拖在左边，数据左端有较多的极端值。\n",
    "#数值的绝对值越大，表明数据分布越不对称，偏斜程度大。\n",
    "print(\"Kurtosis: %f\" % Train_data['price'].kurt())\n",
    "#数据分布顶的尖锐程度。\n",
    "#（1）Kurtosis=0 与正态分布的陡缓程度相同。\n",
    "#（2）Kurtosis>0 比正态分布的高峰更加陡峭——尖顶峰\n",
    "#（3）Kurtosis<0 比正态分布的高峰来得平台——平顶峰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363ec7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data.skew(), Train_data.kurt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7921d41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(Train_data.skew(),color='blue',axlabel ='Skewness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2425f3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(Train_data.kurt(),color='orange',axlabel ='Kurtness')\n",
    "# skew、kurt说明参考https://www.cnblogs.com/wyy1480/p/10474046.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aa9ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3) 查看预测值的具体频数\n",
    "plt.hist(Train_data['price'], orientation = 'vertical',histtype = 'bar', color ='red')\n",
    "plt.show()\n",
    "\n",
    "#查看频数, 大于20000得值极少，其实这里也可以把这些当作特殊得值（异常值）直接用填充或者删掉，再前面进行\n",
    "#orientation = 'vertical' 'horizontal',改变条形图方向\n",
    "#查看预测值具体频数，右边有个较长的尾巴，用log变换来让图更符合正态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6ca052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log变换 z之后的分布较均匀，可以进行log变换进行预测，这也是预测问题常用的trick\n",
    "plt.hist(np.log(Train_data['price']), orientation = 'vertical',histtype = 'bar', color ='red') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c4242f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Box-Cox变换\n",
    "    #Box-Cox变换不支持负值的输入；\n",
    "    # Box-Cox变换对于lognormal and chi-squared分布（对数正态、卡方），表现好于Yeo-Johnson变换；\n",
    "from sklearn.preprocessing import power_transform\n",
    "dft2=power_transform(Train_data[['price']],method='box-cox')\n",
    "plt.hist(dft2, orientation = 'vertical',histtype = 'bar', color ='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9252501f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#yeo-johnson变换\n",
    "#Yeo-Johnson变换的特点在于其可被应用于包含0值和负值的样本中，因此其也被认为是Box-Cox变换在实数域的推广\n",
    "from sklearn.preprocessing import power_transform\n",
    "dft2=power_transform(Train_data[['price']],method='yeo-johnson')\n",
    "plt.hist(dft2, orientation = 'vertical',histtype = 'bar', color ='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37f0e06",
   "metadata": {},
   "source": [
    "# 特征分为类别特征和数字特征，并对类别特征查看unique分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931b2664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分离label即预测值\n",
    "Y_train = Train_data['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a92d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这个区别方式适用于没有直接label coding的数据\n",
    "# 这里不适用，需要人为根据实际含义来区分\n",
    "# 数字特征\n",
    "# numeric_features = Train_data.select_dtypes(include=[np.number])\n",
    "# numeric_features.columns\n",
    "# 类型特征\n",
    "categorical_features = Train_data.select_dtypes(include=[np.object])\n",
    "categorical_features.columns\n",
    "\n",
    "\n",
    "\n",
    "# numerical_fea = list(data_train.select_dtypes(exclude=['object']).columns)\n",
    "# category_fea = list(filter(lambda x: x not in numerical_fea,list(data_train.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b13e834",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['power', 'kilometer', 'v_0', 'v_1', 'v_2', 'v_3', 'v_4', 'v_5', 'v_6', 'v_7', 'v_8', 'v_9', 'v_10', 'v_11', 'v_12', 'v_13','v_14' ]\n",
    "\n",
    "categorical_features = ['name', 'model', 'brand', 'bodyType', 'fuelType', 'gearbox', 'notRepairedDamage', 'regionCode',]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9be0eef",
   "metadata": {},
   "source": [
    "## 特征nunique分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22d15f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征nunique分布\n",
    "#unique() 返回列的所有唯一值（特征的所有唯一值）\n",
    "# nunique() 即返回的是唯一值的个数\n",
    "\n",
    "for cat_fea in categorical_features:\n",
    "    print(cat_fea + \"的特征分布如下：\")\n",
    "    print(\"{}特征有个{}不同的值\".format(cat_fea, Train_data[cat_fea].nunique()))\n",
    "    print(Train_data[cat_fea].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2f5bec",
   "metadata": {},
   "source": [
    "# 数字特征分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2661c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features.append('price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a150f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4c14ad",
   "metadata": {},
   "source": [
    "# 划分数值型变量中的连续变量和离散型变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbacf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#过滤数值型类别特征\n",
    "def get_numerical_serial_fea(data,feas):\n",
    "    numerical_serial_fea = []\n",
    "    numerical_noserial_fea = []\n",
    "    for fea in feas:\n",
    "        temp = data[fea].nunique()\n",
    "        if temp <= 10:\n",
    "            numerical_noserial_fea.append(fea)\n",
    "            continue\n",
    "        numerical_serial_fea.append(fea)\n",
    "    return numerical_serial_fea,numerical_noserial_fea\n",
    "numerical_serial_fea,numerical_noserial_fea = get_numerical_serial_fea(data_train,numerical_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9c38b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_serial_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2eab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_noserial_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc6e554",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1) 相关性分析\n",
    "price_numeric = Train_data[numeric_features]\n",
    "correlation = price_numeric.corr()\n",
    "print(correlation['price'].sort_values(ascending = False),'\\n')\n",
    "#数字特征分析是去做一个相关性的分析。主要是包括v开头的那些匿名特征，power，kilometer。需注意的是，相关性分析只对存在线性关系的变量有意义。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0c1ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f , ax = plt.subplots(figsize = (7, 7))\n",
    "plt.rcParams['font.sans-serif']=['SimHei']\n",
    "plt.rcParams['axes.unicode_minus']=False\n",
    "plt.title('Correlation of Numeric Features with Price',y=1,size=16)\n",
    "sns.set(font=\"simhei\")\n",
    "sns.heatmap(correlation,square = True,  vmax=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474448e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del price_numeric['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18c359b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2) 查看几个特征得 偏度和峰值\n",
    "for col in numeric_features:\n",
    "    print('{:15}'.format(col), \n",
    "          'Skewness: {:05.2f}'.format(Train_data[col].skew()) , \n",
    "          '   ' ,\n",
    "          'Kurtosis: {:06.2f}'.format(Train_data[col].kurt())  \n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d11970",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3) 每个数字特征得分布可视化\n",
    "f = pd.melt(Train_data, value_vars=numeric_features)\n",
    "g = sns.FacetGrid(f, col=\"variable\",  col_wrap=3, sharex=False, sharey=False)\n",
    "g = g.map(sns.distplot, \"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c3f987",
   "metadata": {},
   "source": [
    "## 可以看出匿名特征相对分布均匀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4817fb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4) 数字特征相互之间的关系可视化\n",
    "sns.set()\n",
    "columns = ['price', 'v_12', 'v_8' , 'v_0', 'power', 'v_5',  'v_2', 'v_6', 'v_1', 'v_14']\n",
    "sns.pairplot(Train_data[columns],size = 2 ,kind ='scatter',diag_kind='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4995aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5) 多变量互相回归关系可视化\n",
    "fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6), (ax7, ax8), (ax9, ax10)) = plt.subplots(nrows=5, ncols=2, figsize=(24, 20))\n",
    "# ['v_12', 'v_8' , 'v_0', 'power', 'v_5',  'v_2', 'v_6', 'v_1', 'v_14']\n",
    "# Y_train:分离label即预测值\n",
    "v_12_scatter_plot = pd.concat([Y_train,Train_data['v_12']],axis = 1)\n",
    "sns.regplot(x='v_12',y = 'price', data = v_12_scatter_plot,scatter= True, fit_reg=True, ax=ax1)\n",
    "\n",
    "v_8_scatter_plot = pd.concat([Y_train,Train_data['v_8']],axis = 1)\n",
    "sns.regplot(x='v_8',y = 'price',data = v_8_scatter_plot,scatter= True, fit_reg=True, ax=ax2)\n",
    "\n",
    "v_0_scatter_plot = pd.concat([Y_train,Train_data['v_0']],axis = 1)\n",
    "sns.regplot(x='v_0',y = 'price',data = v_0_scatter_plot,scatter= True, fit_reg=True, ax=ax3)\n",
    "\n",
    "power_scatter_plot = pd.concat([Y_train,Train_data['power']],axis = 1)\n",
    "sns.regplot(x='power',y = 'price',data = power_scatter_plot,scatter= True, fit_reg=True, ax=ax4)\n",
    "\n",
    "v_5_scatter_plot = pd.concat([Y_train,Train_data['v_5']],axis = 1)\n",
    "sns.regplot(x='v_5',y = 'price',data = v_5_scatter_plot,scatter= True, fit_reg=True, ax=ax5)\n",
    "\n",
    "v_2_scatter_plot = pd.concat([Y_train,Train_data['v_2']],axis = 1)\n",
    "sns.regplot(x='v_2',y = 'price',data = v_2_scatter_plot,scatter= True, fit_reg=True, ax=ax6)\n",
    "\n",
    "v_6_scatter_plot = pd.concat([Y_train,Train_data['v_6']],axis = 1)\n",
    "sns.regplot(x='v_6',y = 'price',data = v_6_scatter_plot,scatter= True, fit_reg=True, ax=ax7)\n",
    "\n",
    "v_1_scatter_plot = pd.concat([Y_train,Train_data['v_1']],axis = 1)\n",
    "sns.regplot(x='v_1',y = 'price',data = v_1_scatter_plot,scatter= True, fit_reg=True, ax=ax8)\n",
    "\n",
    "v_14_scatter_plot = pd.concat([Y_train,Train_data['v_14']],axis = 1)\n",
    "sns.regplot(x='v_14',y = 'price',data = v_14_scatter_plot,scatter= True, fit_reg=True, ax=ax9)\n",
    "\n",
    "v_13_scatter_plot = pd.concat([Y_train,Train_data['v_13']],axis = 1)\n",
    "sns.regplot(x='v_13',y = 'price',data = v_13_scatter_plot,scatter= True, fit_reg=True, ax=ax10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cf0748",
   "metadata": {},
   "source": [
    "# 类别特征分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6ab11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1) unique分布\n",
    "for fea in categorical_features:\n",
    "    print(Train_data[fea].nunique())\n",
    "    \n",
    "# 对于一维数组或者列表，unique函数去除其中重复的元素，并按元素由大到小返回一个新的无元素重复的元组或者列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ea967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508fbaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2) 类别特征箱形图可视化\n",
    "\n",
    "# 因为 name和 regionCode的类别太稀疏了，这里我们把不稀疏的几类画一下\n",
    "categorical_features = ['model',\n",
    " 'brand',\n",
    " 'bodyType',\n",
    " 'fuelType',\n",
    " 'gearbox',\n",
    " 'notRepairedDamage']\n",
    "for c in categorical_features:\n",
    "    Train_data[c] = Train_data[c].astype('category')\n",
    "    if Train_data[c].isnull().any():\n",
    "        Train_data[c] = Train_data[c].cat.add_categories(['MISSING'])\n",
    "        Train_data[c] = Train_data[c].fillna('MISSING')\n",
    "\n",
    "def boxplot(x, y, **kwargs):\n",
    "    sns.boxplot(x=x, y=y)\n",
    "    x=plt.xticks(rotation=90)\n",
    "\n",
    "f = pd.melt(Train_data, id_vars=['price'], value_vars=categorical_features)\n",
    "g = sns.FacetGrid(f, col=\"variable\",  col_wrap=2, sharex=False, sharey=False, size=5)\n",
    "g = g.map(boxplot, \"value\", \"price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8b014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba3b55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3) 类别特征的小提琴图可视化\n",
    "catg_list = categorical_features\n",
    "target = 'price'\n",
    "for catg in catg_list :\n",
    "    sns.violinplot(x=catg, y=target, data=Train_data)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89795cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['model',\n",
    " 'brand',\n",
    " 'bodyType',\n",
    " 'fuelType',\n",
    " 'gearbox',\n",
    " 'notRepairedDamage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3461b79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4) 类别特征的柱形图可视化\n",
    "def bar_plot(x, y, **kwargs):\n",
    "    sns.barplot(x=x, y=y)\n",
    "    x=plt.xticks(rotation=90)\n",
    "\n",
    "f = pd.melt(Train_data, id_vars=['price'], value_vars=categorical_features)\n",
    "g = sns.FacetGrid(f, col=\"variable\",  col_wrap=2, sharex=False, sharey=False, size=5)\n",
    "g = g.map(bar_plot, \"value\", \"price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653097a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  5) 类别特征的每个类别频数可视化(count_plot)\n",
    "def count_plot(x,  **kwargs):\n",
    "    sns.countplot(x=x)\n",
    "    x=plt.xticks(rotation=90)\n",
    "\n",
    "f = pd.melt(Train_data,  value_vars=categorical_features)\n",
    "g = sns.FacetGrid(f, col=\"variable\",  col_wrap=2, sharex=False, sharey=False, size=5)\n",
    "g = g.map(count_plot, \"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bed041",
   "metadata": {},
   "source": [
    "# 用pandas_profiling生成数据报告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaf1b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#用pandas_profiling生成一个较为全面的可视化和数据报告(较为简单、方便) 最终打开html文件即可\n",
    "import pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3468dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfr = pandas_profiling.ProfileReport(Train_data)\n",
    "pfr.to_file(\"./example.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c8339d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee7d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 所给出的EDA步骤为广为普遍的步骤，在实际的不管是工程还是比赛过程中，这只是最开始的一步，也是最基本的一步。\n",
    "# 接下来一般要结合模型的效果以及特征工程等来分析数据的实际建模情况，根据自己的一些理解，查阅文献，对实际问题做出判断和深入的理解。\n",
    "# 最后不断进行EDA与数据处理和挖掘，来到达更好的数据结构和分布以及较为强势相关的特征\n",
    "# 数据探索在机器学习中我们一般称为EDA（Exploratory Data Analysis）：\n",
    "# 是指对已有的数据（特别是调查或观察得来的原始数据）在尽量少的先验假定下进行探索，通过作图、制表、方程拟合、计算特征量等手段探索数据的结构和规律的一种数据分析方法。\n",
    "# 数据探索有利于我们发现数据的一些特性，数据之间的关联性，对于后续的特征构建是很有帮助的。\n",
    "# 对于数据的初步分析（直接查看数据，或.sum(), .mean()，.descirbe()等统计函数）可以从：样本数量，训练集数量，是否有时间特征，是否是时许问题，特征所表示的含义（非匿名特征），特征类型（字符类似，int，float，time），特征的缺失情况（注意缺失的在数据中的表现形式，有些是空的有些是”NAN”符号等），特征的均值方差情况。\n",
    "# 分析记录某些特征值缺失占比30%以上样本的缺失处理，有助于后续的模型验证和调节，分析特征应该是填充（填充方式是什么，均值填充，0填充，众数填充等），还是舍去，还是先做样本分类用不同的特征模型去预测。\n",
    "# 对于异常值做专门的分析，分析特征异常的label是否为异常值（或者偏离均值较远或者事特殊符号）,异常值是否应该剔除，还是用正常值填充，是记录异常，还是机器本身异常等。\n",
    "# 对于Label做专门的分析，分析标签的分布情况等。\n",
    "# 进步分析可以通过对特征作图，特征和label联合做图（统计图，离散图），直观了解特征的分布情况，通过这一步也可以发现数据之中的一些异常值等，通过箱型图分析一些特征值的偏离情况，对于特征和特征联合作图，对于特征和label联合作图，分析其中的一些关联性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fdd94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#循环特征选择\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data=pd.read_csv('.csv')\n",
    "x=data.iloc[:,0:14] #前十四个字段做自变量\n",
    "y=data.iloc[:,-1].values #最后一个做应变量\n",
    "knn=KNeighborsClassifier(n_neighbors=4)\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "sfs1=SFS(knn,k_features=4,forward=True,floating=False,verbose=2,scoring='accuracy',cv=0)\n",
    "sfs1=sfs1.fit(x,y)\n",
    "sfs1.subset_\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
